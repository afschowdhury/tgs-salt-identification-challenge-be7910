{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891fc076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# ========== FIX 1: Extract lib files ==========\n",
    "!unzip -q /kaggle/input/tgs-salt-identification-challenge/flamingo.zip -d /kaggle/working/\n",
    "!mv /kaggle/working/flamingo/lib /kaggle/working/lib\n",
    "\n",
    "# ========== FIX 2: Add to Python path ==========\n",
    "import sys\n",
    "sys.path.insert(0, '/kaggle/working/lib')\n",
    "\n",
    "# ========== Now the imports will work ==========\n",
    "from train_utils import get_model\n",
    "from postprocess import zero_masks_inplace\n",
    "\n",
    "# Step 1: Setup environment\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = json.load(open('/kaggle/input/tgs-salt-identification-challenge/infallible_lamport.json'))\n",
    "snapshot = torch.load('/kaggle/input/tgs-salt-identification-challenge/Oct09_23_17_wider_unet_224pad_medium_infallible_lamport_val_lb.pth', map_location=device)\n",
    "\n",
    "# Step 2: Prepare the model\n",
    "model = get_model(config['model'],\n",
    "                  num_classes=config['num_classes'],\n",
    "                  num_channels=1,\n",
    "                  pretrained=False).to(device)\n",
    "\n",
    "model.load_state_dict(snapshot['model'])\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Load test data\n",
    "test_folder = '/kaggle/input/tgs-salt-identification-challenge/test'\n",
    "test_images = sorted([os.path.join(test_folder, f) for f in os.listdir(test_folder) if f.endswith('.png')])\n",
    "test_ids = [os.path.basename(f).replace('.png', '') for f in test_images]\n",
    "\n",
    "# Step 4: Define the test dataset\n",
    "class SaltTestDataset(Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.paths = image_paths\n",
    "        self.ids = [os.path.basename(p).replace('.png', '') for p in self.paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.paths[idx])\n",
    "        image = np.array(image, dtype=np.float32) / 255.0\n",
    "        image = np.expand_dims(image, axis=0)  # shape: (1, 101, 101)\n",
    "        return torch.tensor(image), self.ids[idx]\n",
    "\n",
    "# Step 5: Prepare DataLoader\n",
    "dataset = SaltTestDataset(test_images)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 6: Generate predictions\n",
    "pred_masks = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in tqdm(loader, desc=\"Predicting\"):\n",
    "        images = images.to(device)\n",
    "        output = model(images)\n",
    "\n",
    "        # Process the model output\n",
    "        masks = output.sigmoid().cpu().numpy()\n",
    "        masks = (masks > 0.45).astype(np.uint8)  # Apply threshold\n",
    "\n",
    "        for mask in masks:\n",
    "            mask = np.squeeze(mask)\n",
    "            pred_masks.append(mask)\n",
    "\n",
    "        image_ids.extend(ids)\n",
    "\n",
    "# Step 7: Run-Length Encoding (RLE) for submission\n",
    "def rle_encode(mask):\n",
    "    pixels = mask.T.flatten()  # Fix: Use Fortran-order flattening\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(map(str, runs)) if len(runs) else ''\n",
    "\n",
    "# Step 8: Format submission\n",
    "encoded_masks = [rle_encode(mask) for mask in pred_masks]\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': image_ids,\n",
    "    'rle_mask': encoded_masks\n",
    "})\n",
    "\n",
    "\n",
    "# Step 9: Save the submission file\n",
    "submission_df.to_csv('/kaggle/working/submission.csv.gz', index=False, compression='gzip')\n",
    "\n",
    "print(\"âœ… Submission saved to /kaggle/working/submission.csv.gz\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
