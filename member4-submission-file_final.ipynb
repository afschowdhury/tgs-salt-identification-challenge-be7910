{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10151,"databundleVersionId":59042,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-30T17:10:15.636052Z","iopub.execute_input":"2025-04-30T17:10:15.636365Z","iopub.status.idle":"2025-04-30T17:10:18.180737Z","shell.execute_reply.started":"2025-04-30T17:10:15.636342Z","shell.execute_reply":"2025-04-30T17:10:18.179877Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/tgs-salt-identification-challenge/depths.csv\n/kaggle/input/tgs-salt-identification-challenge/sample_submission.csv\n/kaggle/input/tgs-salt-identification-challenge/train.zip\n/kaggle/input/tgs-salt-identification-challenge/competition_data.zip\n/kaggle/input/tgs-salt-identification-challenge/test.zip\n/kaggle/input/tgs-salt-identification-challenge/train.csv\n/kaggle/input/tgs-salt-identification-challenge/flamingo.zip\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ===========================================\n# Step 8: Prediction and Submission File Generation (Using Overall Best Model)\n# ===========================================\n\n# --- Find the Overall Best Model ---\noverall_best_iou = -1.0\nbest_config_name = None\nfor config_name, metrics in best_model_metrics.items():\n    if metrics['best_val_iou'] > overall_best_iou:\n        overall_best_iou = metrics['best_val_iou']\n        best_config_name = config_name\n\nprint(f\"\\n--- Overall Best Model based on Validation IoU: {best_config_name} (IoU: {overall_best_iou:.4f}) ---\")\n\n# --- Run-Length Encoding Function ---\ndef rle_encode(img):\n    pixels = img.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n# --- Prediction Function ---\ndef predict_test(model, test_loader, device, threshold=0.5):\n    model.eval()\n    predictions = {}\n    test_pbar = tqdm(test_loader, desc=\"Predicting\", leave=False)\n    with torch.no_grad():\n        for images, image_ids in test_pbar:\n            images = images.to(device)\n            outputs = model(images)\n            probs = torch.sigmoid(outputs)\n            probs_resized = F.interpolate(probs, size=(101, 101), mode='bilinear', align_corners=False)\n            preds_binary = (probs_resized > threshold).cpu().numpy().astype(np.uint8)\n            for i, img_id in enumerate(image_ids):\n                 pred_mask = preds_binary[i].squeeze()\n                 predictions[img_id] = pred_mask\n    return predictions\n\n# --- Load the Overall Best Model ---\n# Re-instantiate the model architecture for the best config\nbest_backbone = best_config_name.split('_')[0]\nbest_model = UNet(backbone_name=best_backbone, pretrained=False).to(DEVICE) # No need for pretrained weights now\n\nbest_model_path = f\"models/best_model_{best_config_name}.pth\"\nif os.path.exists(best_model_path):\n    print(f\"Loading overall best model from: {best_model_path}\")\n    best_model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))\nelse:\n    print(f\"Error: Best model path not found ({best_model_path}). Cannot generate submission.\")\n    # Handle error appropriately, maybe exit or use a default model if available\n\n# --- Perform Prediction with Best Model ---\nif os.path.exists(best_model_path):\n    test_predictions = predict_test(best_model, test_loader, DEVICE, threshold=0.5) # Adjust threshold if needed\n\n    # --- Generate Submission File ---\n    submission_data = []\n    for img_id in tqdm(test_ids, desc=\"Encoding\"): # Use sorted test_ids\n        if img_id in test_predictions:\n            rle = rle_encode(test_predictions[img_id])\n        else:\n            rle = ''\n            print(f\"Warning: Prediction missing for image ID: {img_id}\")\n        submission_data.append({'id': img_id, 'rle_mask': rle})\n\n    submission_df = pd.DataFrame(submission_data)\n    submission_df.to_csv('submission.csv', index=False)\n\n    print(\"\\n--- Submission File Generated: submission.csv ---\")\n    print(submission_df.head())\nelse:\n    print(\"Submission file not generated due to missing best model.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T17:11:19.839467Z","iopub.execute_input":"2025-04-30T17:11:19.839779Z","iopub.status.idle":"2025-04-30T17:11:19.940619Z","shell.execute_reply.started":"2025-04-30T17:11:19.839755Z","shell.execute_reply":"2025-04-30T17:11:19.939378Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/63944350.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moverall_best_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mbest_config_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbest_model_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_val_iou'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moverall_best_iou\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moverall_best_iou\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_val_iou'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'best_model_metrics' is not defined"],"ename":"NameError","evalue":"name 'best_model_metrics' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"print(\"\\nZipping output files...\")\nif os.path.exists(\"models\"):\n    !zip -rq models.zip /kaggle/working/models # Use -q for quiet, -r for recursive\n    print(\"models.zip created.\")\nif os.path.exists(\"results\"):\n    !zip -rq results.zip /kaggle/working/results\n    print(\"results.zip created.\")\n\nprint(\"\\n--- Script Finished ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-30T17:11:40.148828Z","iopub.execute_input":"2025-04-30T17:11:40.149143Z","iopub.status.idle":"2025-04-30T17:11:40.156270Z","shell.execute_reply.started":"2025-04-30T17:11:40.149119Z","shell.execute_reply":"2025-04-30T17:11:40.155187Z"}},"outputs":[{"name":"stdout","text":"\nZipping output files...\n\n--- Script Finished ---\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}